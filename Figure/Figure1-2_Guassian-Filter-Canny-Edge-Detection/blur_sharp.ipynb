{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blurring(Gaussiann) Filter Exp for Large objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]\n",
      "pytorch version:  2.0.1\n",
      "torchvision version:  0.15.2\n",
      "cuda version:  11.7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torchvision\n",
    "\n",
    "# python version \n",
    "print(\"python version: \", sys.version)\n",
    "\n",
    "# pytorch version, torchvision version\n",
    "print(\"pytorch version: \", torch.__version__)\n",
    "print(\"torchvision version: \", torchvision.__version__)\n",
    "\n",
    "# cuda version\n",
    "print(\"cuda version: \", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = np.random.uniform(0, 255, size=(80, 3))\n",
    "\n",
    "def parse_detections(results):\n",
    "    detections = results.pandas().xyxy[0]\n",
    "    detections = detections.to_dict()\n",
    "    boxes, colors, names = [], [], []\n",
    "\n",
    "    for i in range(len(detections[\"xmin\"])):\n",
    "        confidence = detections[\"confidence\"][i]\n",
    "        if confidence < 0.2:\n",
    "            continue\n",
    "        xmin = int(detections[\"xmin\"][i])\n",
    "        ymin = int(detections[\"ymin\"][i])\n",
    "        xmax = int(detections[\"xmax\"][i])\n",
    "        ymax = int(detections[\"ymax\"][i])\n",
    "        name = detections[\"name\"][i]\n",
    "        category = int(detections[\"class\"][i])\n",
    "        color = COLORS[category]\n",
    "\n",
    "        boxes.append((xmin, ymin, xmax, ymax))\n",
    "        colors.append(color)\n",
    "        names.append(name)\n",
    "    return boxes, colors, names\n",
    "\n",
    "\n",
    "def draw_detections(boxes, colors, names, img):\n",
    "    for box, color, name in zip(boxes, colors, names):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (xmin, ymin),\n",
    "            (xmax, ymax),\n",
    "            color, \n",
    "            2)\n",
    "\n",
    "        cv2.putText(img, name, (xmin, ymin - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2,\n",
    "                    lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def plotAndSaveOriginGaussianResult(model=None, image_url=None, save_number=None, kernel_size=None, sigma=None):\n",
    "    # model\n",
    "    img = np.array(Image.open(requests.get(image_url, stream=True).raw))\n",
    "    img = cv2.resize(img, (640, 640))\n",
    "    rgb_img = img.copy()\n",
    "    img = np.float32(img) / 255\n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    \n",
    "    \n",
    "    # original rgb_img forward\n",
    "    results = model([rgb_img])\n",
    "    boxes, colors, names = parse_detections(results)\n",
    "    detections = draw_detections(boxes, colors, names, rgb_img.copy())\n",
    "    Image.fromarray(detections)\n",
    "    # save the original rgb_img forward result\n",
    "    image = Image.fromarray(detections)\n",
    "    image.save(f\"./results/{save_number}_origin.png\")\n",
    "    \n",
    "    # gaussian filtered rgb_img forward\n",
    "    rgb_tensor = torch.from_numpy(rgb_img)\n",
    "    gaussian_teacher = transforms.GaussianBlur(kernel_size=kernel_size, sigma=sigma)\n",
    "    gaussian_rgb_tensor = gaussian_teacher(rgb_tensor)\n",
    "    gaussian_rgb_img = gaussian_rgb_tensor.numpy()\n",
    "    # gaussian_rgb_img += rgb_tensor.numpy()\n",
    "    results_gaussian = model([gaussian_rgb_img])\n",
    "    boxes, colors, names = parse_detections(results_gaussian)\n",
    "    detections = draw_detections(boxes, colors, names, rgb_img.copy())\n",
    "    Image.fromarray(detections)\n",
    "    # save the gaussian filtered rgb_img forward result\n",
    "    image = Image.fromarray(detections)\n",
    "    sigma = str(sigma).replace(\".\", \"\")[5]\n",
    "    image.save(f\"./results/{save_number}_gaussian_k{kernel_size}_s{sigma}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/hslee/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-9-30 Python-3.11.9 torch-2.0.1 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 48640MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 0 done\n",
      "image 1 done\n",
      "image 2 done\n",
      "image 3 done\n",
      "image 4 done\n",
      "image 5 done\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "url_list = [\n",
    "    \"http://farm8.staticflickr.com/7218/7048835433_97d58c41dd_z.jpg\",\n",
    "    \"http://farm8.staticflickr.com/7069/7144544497_4ce8268017_z.jpg\",\n",
    "    \"http://farm9.staticflickr.com/8331/8395076888_929af4a595_z.jpg\",\n",
    "    \"http://farm8.staticflickr.com/7216/7398739548_991338f382_z.jpg\",\n",
    "    \"http://farm1.staticflickr.com/48/131364607_433f149962_z.jpg\",\n",
    "    \"http://farm1.staticflickr.com/91/239378460_3fc1f9a101_z.jpg\",\n",
    "]\n",
    "\n",
    "for i, url in enumerate(url_list):\n",
    "    plotAndSaveOriginGaussianResult(model=model, image_url=url, save_number=i, kernel_size=3, sigma=(0.1, 1.0))\n",
    "    plotAndSaveOriginGaussianResult(model=model, image_url=url, save_number=i, kernel_size=3, sigma=(0.1, 2.0))\n",
    "    plotAndSaveOriginGaussianResult(model=model, image_url=url, save_number=i, kernel_size=3, sigma=(0.1, 3.0))\n",
    "    plotAndSaveOriginGaussianResult(model=model, image_url=url, save_number=i, kernel_size=5, sigma=(0.1, 2.0))\n",
    "    print(f\"image {i} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Step 1: Get the image from the URL\n",
    "img_url = \"http://farm8.staticflickr.com/7218/7048835433_97d58c41dd_z.jpg\"\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Step 2: Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blurring(Gaussian) Filtered image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "img_url = \"http://farm8.staticflickr.com/7218/7048835433_97d58c41dd_z.jpg\"\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "gaussian_filter = transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "img_gaussian = gaussian_filter(img)\n",
    "plt.imshow(img_gaussian)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "gaussian_filter = transforms.GaussianBlur(kernel_size=9, sigma=(0.1, 2.0))\n",
    "img_gaussian = gaussian_filter(img)\n",
    "plt.imshow(img_gaussian)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpening Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Get the image from the URL\n",
    "img_url = \"http://farm8.staticflickr.com/7218/7048835433_97d58c41dd_z.jpg\"\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# black and white\n",
    "img = img.convert('L')\n",
    "\n",
    "# Step 2: Display the image\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: uint8, shape: (424, 640)\n"
     ]
    }
   ],
   "source": [
    "# Canny filter\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Step 1: Get the image from the URL\n",
    "img_url = \"http://farm8.staticflickr.com/7218/7048835433_97d58c41dd_z.jpg\"\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# black and white\n",
    "img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
    "print(f\"data type: {img.dtype}, shape: {img.shape}\")\n",
    "canny_filter = cv2.Canny(img, 100, 200)\n",
    "\n",
    "temp = img.copy()\n",
    "img += canny_filter # local feature enhancement\n",
    "img = img - temp\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(80, 3))\n",
    "\n",
    "def parse_detections(results):\n",
    "    detections = results.pandas().xyxy[0]\n",
    "    detections = detections.to_dict()\n",
    "    boxes, colors, names = [], [], []\n",
    "\n",
    "    for i in range(len(detections[\"xmin\"])):\n",
    "        confidence = detections[\"confidence\"][i]\n",
    "        if confidence < 0.2:\n",
    "            continue\n",
    "        xmin = int(detections[\"xmin\"][i])\n",
    "        ymin = int(detections[\"ymin\"][i])\n",
    "        xmax = int(detections[\"xmax\"][i])\n",
    "        ymax = int(detections[\"ymax\"][i])\n",
    "        name = detections[\"name\"][i]\n",
    "        category = int(detections[\"class\"][i])\n",
    "        color = COLORS[category]\n",
    "\n",
    "        boxes.append((xmin, ymin, xmax, ymax))\n",
    "        colors.append(color)\n",
    "        names.append(name)\n",
    "    return boxes, colors, names\n",
    "\n",
    "\n",
    "def draw_detections(boxes, colors, names, img):\n",
    "    for box, color, name in zip(boxes, colors, names):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (xmin, ymin),\n",
    "            (xmax, ymax),\n",
    "            color, \n",
    "            2)\n",
    "\n",
    "        cv2.putText(img, name, (xmin, ymin - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2,\n",
    "                    lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def plotAndSaveCannyResult(model=None, image_url=None, save_number=None, kernel_size=None, sigma=None):\n",
    "    # model\n",
    "    img = np.array(Image.open(requests.get(image_url, stream=True).raw))\n",
    "    print(img.shape)\n",
    "    img = cv2.resize(img, (640, 640))\n",
    "    rgb_img = img.copy()\n",
    "    img = np.float32(img) / 255\n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    \n",
    "    # canny filtered rgb_img forward\n",
    "    rgb_tensor = torch.from_numpy(rgb_img)\n",
    "    print(f\"data type: {rgb_img.dtype}, shape: {rgb_img.shape}\")\n",
    "    canny_teacher = cv2.Canny(rgb_img, 100, 200)\n",
    "    canny_teacher = torch.from_numpy(canny_teacher)\n",
    "    \n",
    "    # torch([640, 640]) -> torch([640, 640, 1])\n",
    "    canny_teacher = canny_teacher.unsqueeze(2)\n",
    "    rgb_tensor = rgb_tensor + canny_teacher\n",
    "    rgb_tensor = rgb_tensor.numpy()\n",
    "    \n",
    "    results_canny = model([rgb_tensor])\n",
    "    boxes, colors, names = parse_detections(results_canny)\n",
    "    detections = draw_detections(boxes, colors, names, rgb_img.copy())\n",
    "    Image.fromarray(detections)\n",
    "    # save the canny filtered rgb_img forward result\n",
    "    image = Image.fromarray(detections)\n",
    "    sigma = str(sigma).replace(\".\", \"\")[5]\n",
    "    image.save(f\"./results/{save_number}_canny.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/hslee/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-9-30 Python-3.11.9 torch-2.0.1 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 48640MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 640, 3)\n",
      "data type: uint8, shape: (640, 640, 3)\n",
      "image 0 done\n",
      "(480, 640, 3)\n",
      "data type: uint8, shape: (640, 640, 3)\n",
      "image 1 done\n",
      "(640, 599, 3)\n",
      "data type: uint8, shape: (640, 640, 3)\n",
      "image 2 done\n",
      "(427, 640, 3)\n",
      "data type: uint8, shape: (640, 640, 3)\n",
      "image 3 done\n",
      "(480, 640, 3)\n",
      "data type: uint8, shape: (640, 640, 3)\n",
      "image 4 done\n",
      "(464, 640, 3)\n",
      "data type: uint8, shape: (640, 640, 3)\n",
      "image 5 done\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "url_list = [\n",
    "    \"http://farm8.staticflickr.com/7218/7048835433_97d58c41dd_z.jpg\",\n",
    "    \"http://farm8.staticflickr.com/7069/7144544497_4ce8268017_z.jpg\",\n",
    "    \"http://farm9.staticflickr.com/8331/8395076888_929af4a595_z.jpg\",\n",
    "    \"http://farm8.staticflickr.com/7216/7398739548_991338f382_z.jpg\",\n",
    "    \"http://farm1.staticflickr.com/48/131364607_433f149962_z.jpg\",\n",
    "    \"http://farm1.staticflickr.com/91/239378460_3fc1f9a101_z.jpg\",\n",
    "]\n",
    "\n",
    "for i, url in enumerate(url_list):\n",
    "    plotAndSaveCannyResult(model=model, image_url=url, save_number=i, kernel_size=3, sigma=(0.1, 1.0))\n",
    "    print(f\"image {i} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 800, 1216])\n",
      "torch.Size([2, 256, 100, 152])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "tensor = torch.randn(2, 3, 800, 1216)\n",
    "\n",
    "# make  [2, 3, 800, 1216] to [2, 256, 100, 152]\n",
    "gaussianT_adaptation_layer = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "print(tensor.shape)\n",
    "tensor = gaussianT_adaptation_layer(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original image histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"http://farm8.staticflickr.com/7218/7048835433_97d58c41dd_z.jpg\"\n",
    "\n",
    "# image show\n",
    "response = requests.get(image_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"http://farm8.staticflickr.com/7218/7048835433_97d58c41dd_z.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "original_image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "original_image = np.array(original_image)\n",
    "plt.hist(original_image.ravel(),256,[0,256]);\n",
    "plt.ylim([0, 18000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian filter image\n",
    "\n",
    "gaussian_filter = cv.GaussianBlur(original_image, (5, 5), 0)\n",
    "plt.hist(gaussian_filter.ravel(),256,[0,256]); \n",
    "plt.ylim([0, 18000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. canny filtered image\n",
    "edges = cv.Canny(original_image, 100, 200)\n",
    "edges = edges.reshape(edges.shape[0], edges.shape[1], 1)\n",
    "canny_image = original_image + edges\n",
    "plt.hist(canny_image.ravel(),256,[0,256]);\n",
    "plt.ylim([0, 18000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
